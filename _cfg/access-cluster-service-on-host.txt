how to access cluster service (using svc domain name url) on host

- 
  . in general, coresdns dns service in cluster is not available for accessing on host machine. 
  . using following setting to access domain name url of cluster service on host machine.

rem:
  cluster dns (coredns) ip : (static) 10.96.0.2
  public dns server ip : 180.76.76.76 

- install dnsmasq binary
# dnf install dnsmasq 

- enable dnsmasq using NetworkManager
# nano /etc/NetworkManager/NetworkManager.conf 
-- add in [main] section 
dns=dnsmasq 
--

- set dnsmasq configuration for kube cluster ( use dnsmasq to forward all kube svc domain cluster.local to coredns on 10.96.0.2) 
# nano /etc/NetworkManager/dnsmasq.d/kube.conf 
-- add 
server=/cluster.local/10.96.0.2 
--
( 
    OR, forward dns request of domain cluster.local to master 10.0.0.101 ,
       
      and setting dnsmasq on master 10.0.0.101 to forward all dns traffic on host to coredns at 10.96.0.2,
      ( 
        - change NetworkManager config file to use dnsmasq service
        file: /etc/NetworkManager/NetworkManager.conf
        -- change, add  (use NetworkManager to manager dnsmasq service)
        [main]
        dns=dnsmasq
        --
        (restart NetworkManager will start dnsmasq service and will change /etc/resolv.conf to use nameserver 127.0.0.1, 
          dnsmasq service will listen on 127.0.0.1:53 udp)

        -create dnsmasq resolv file (upper dns resolver)
        file: /etc/resolv.dnsmasq.conf (dns resolver)
          --
          nameserver 10.96.0.2
          search default.svc.cluster.local svc.cluster.local cluster.local
          --
        
        file: /etc/NetworkManager/dnsmasq.d/kube.conf (not need, as we forward all dns request to uppper dns resolver)
          --
          server=/cluster.local/10.96.0.2
          --
      ) and set dnsmasq listen address 127.0.0.1, 10.0.0.101. 10.0.0.101 is used to server lan request
      ( 
        - copy /etc/dnsmasq.conf to /etc/NetworkManager/dnsmasq.d/ directory
        # cp /etc/dnsmasq.conf /etc/NetworkManager/dnsmasq.d/.

        - change dnsmasq config file to set dnsmasq listen address, addition hosts file, resolv file, address list, and servers

        file: /etc/NetworkManager/dnsmasq.d/dnsmasq.conf
          -- change and add
          # resolv file (to define upper resolver of dnsmasq service)
          resolv-file=/etc/resolv.dnsmasq.conf
          # addon hosts file (same format as /etc/hosts)
          addn-hosts=/etc/hosts
          # listen address of dnsmasq service
          listen-address=127.0.0.1,10.0.0.101
          # address list of hostname and its ip address
          # address=/node1/10.0.0.101
          # server to define domain and its dns resolver ip address 
          # server=/cluster.local/10.96.0.2
          --
      )
      finally, change configmap of coredns to forward all traffic other than cluster domain dns request to 
        external public dns server 180.76.76.76 
        
        -- configmap contents: -n kube-system configmap coredns - change
          forward . 180.76.76.76:53
        --
      and set client machine on lan using 10.0.0.101 (master) as dns server. 
        
        -- file: /etc/sysconfig/network-scripts/ifcfg-ens192
          DNS1=10.0.0.101
        --

    i.e., dns request flow as:
    dns request (from client) pass to (according to host dns setting ) 
      -> dns server 10.0.0.101:53 
        -> listen on :53 by dnsmasq (on 127.0.0.1:53 of master node, 10.0.0.101:53) 
          -> dnsmasq forward to 10.96.0.2 (coredns) 
            -> coredns parsing domain cluster.local 
              -> domain other than cluster.local, forward by coredns to 
                -> 180.76.76.76 (external public dns server)
    ref: dnsmasq process flow -
           1. check dns cache
           2. if (1) fail, resolv using hosts file of host machine
           3. if (2) fail, forward to upper dns resolver machine

)


- add static route to forward all traffic to 10.96.0.0/16 through gateway 10.0.0.101 (master node) 
# route add -net 10.96.0.0 netmask 255.255.0.0 gw 10.0.0.101 
# route -v
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         _gateway        0.0.0.0         UG    100    0        0 ens192
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 ens192
10.96.0.0       node1           255.255.0.0     UG    0      0        0 ens192

- restart NetworkManager to make dnsmasq take effect 
# systemctl restart NetworkManager 

- check /etc/resolv.conf 
# cat /etc/resolv.conf 
# Generated by NetworkManager
nameserver 127.0.0.1
           ^
           this means, dns request are forward to localhost 127.0.0.1 which is handled by dnsmasq.



- change coredns.yaml (change configmap of coredns to as following )
remark:
  change un-resolved dns parsing to forward to 180.76.76.76 (public dns server)

# kubectl -n kube-system describe configmap coredns
Name:         coredns
Namespace:    kube-system
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration:
                {"apiVersion":"v1","data":{"Corefile":".:53 {\n    errors\n    health\n    kubernetes cluster.local  10.96.0.0/16 {\n      pods insecure\n...

Data
====
Corefile:
----
.:53 {
    errors
    health
    kubernetes cluster.local  10.96.0.0/16 {
      pods insecure
      upstream
      fallthrough in-addr.arpa ip6.arpa
    }
    prometheus :9153
    #forward . /etc/resolv.conf
    forward . 180.76.76.76:53
    cache 30
    loop
    reload
    loadbalance
}

Events:  <none>


--------------------------
- check it is working

. cluster service as following:
# kubectl get svc -o wide
NAME           TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE   SELECTOR
echo-server    LoadBalancer   10.96.130.180   10.0.0.226    446:41730/TCP    5d    app=tcp-echo-server
hello          ClusterIP      10.96.171.212   <none>        80/TCP           5d    app=hello,department=dev
hostnames      ClusterIP      10.96.65.138    <none>        80/TCP           5d    app=hostnames
kubernetes     ClusterIP      10.96.0.1       <none>        443/TCP          5d    <none>
myip           LoadBalancer   10.96.207.209   10.0.0.225    8080:37559/TCP   5d    app=myip
nginx-svc-lb   LoadBalancer   10.96.2.196     10.0.0.224    80:33951/TCP     5d    app=nginx

1. 
# nslookup kubernetes.default.svc.cluster.local
Server:         127.0.0.1
Address:        127.0.0.1#53

Name:   kubernetes.default.svc.cluster.local
Address: 10.96.0.1

2.
# nslookup kube-dns.kube-system.svc.cluster.local
Server:         127.0.0.1
Address:        127.0.0.1#53

Name:   kube-dns.kube-system.svc.cluster.local
Address: 10.96.0.2

3.
# nslookup myip.default.svc.cluster.local
Server:         127.0.0.1
Address:        127.0.0.1#53

Name:   myip.default.svc.cluster.local
Address: 10.96.207.209

4.
# ping kubernetes.default.svc.cluster.local

5. 
# curl -o- myip.default.svc.cluster.local:8080
HOSTNAME:myip-7564d897c9-trkcx IP:10.244.2.34
# curl -o- myip.default.svc.cluster.local:8080
HOSTNAME:myip-7564d897c9-qf2bq IP:10.244.2.30

6.
# curl -o- hostnames.default.svc.cluster.local
hostnames-85bc9c579-6lbmw
[root@node ~]# curl -o- hostnames.default.svc.cluster.local
hostnames-85bc9c579-csqjg

